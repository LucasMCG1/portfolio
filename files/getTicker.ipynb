{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from urllib.request import urlopen\n",
    "from urllib import request\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "from selenium.common.exceptions import UnexpectedAlertPresentException\n",
    "\n",
    "merchants = pd.read_excel('fuzz.xlsx')\n",
    "w = 'wiki'\n",
    "c = 'crunch'\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "profile = webdriver.FirefoxProfile()\n",
    "profile.set_preference(\"general.useragent.override\",\"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:60.0) Gecko/20100101 Firefox/60.0\")\n",
    "driver = webdriver.Firefox(profile, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GET_TICKER VERSION 1\n",
    "\n",
    "\n",
    "# def getParentWebpage(html):\n",
    "#     try:\n",
    "#         trs = html.find('table', {'class': 'infobox vcard'}).find_all('tr')\n",
    "#         for tr in trs:\n",
    "#             if 'Parent' in tr.text:\n",
    "#                 path = str(tr.find('td').find('a').get('href'))\n",
    "#                 driver.get('https://en.wikipedia.org' + path)\n",
    "#                 html = BeautifulSoup(driver.page_source, \"lxml\")\n",
    "#                 return getParentWebpage(html)\n",
    "#         return html\n",
    "#     except:\n",
    "#         return html\n",
    "\n",
    "# def getTickerOnline(merchant):\n",
    "#     try:\n",
    "#         driver.get('https://google.com/search?q=' + str(merchant) + ' wikipedia')\n",
    "#         html = BeautifulSoup(driver.page_source, \"lxml\")\n",
    "#         for res in html.find_all('div', {'class': 'g'}):\n",
    "#             if 'wikipedia' in res.find('a').get('href'):\n",
    "#                 driver.get(res.find('a').get('href'))\n",
    "#                 html = BeautifulSoup(driver.page_source, \"lxml\")\n",
    "#                 break\n",
    "#         trs = html.find('table', {'class': 'infobox vcard'}).find_all('tr')        \n",
    "#         for tr in trs:\n",
    "#             if 'traded' in tr.text.lower():\n",
    "#                 return tr.find('a', {'rel':'nofollow'}).text\n",
    "#         html = getParentWebpage(html)\n",
    "#         for tr in trs:    \n",
    "#             if 'private' in tr.text.lower():\n",
    "#                 return 'PRIVATE'\n",
    "#         return 'ERR'\n",
    "#     except:\n",
    "#         return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GET_TICKER VERSION 2 (WIKIPEDIA)\n",
    "\n",
    "\n",
    "def getTickerW(merchant):\n",
    "    html = getHTMLW(merchant)\n",
    "    if isTradedW(html) != False:\n",
    "        return isTradedW(html)\n",
    "    if isPrivateW(html) == True:\n",
    "        return 'PRIVATE'\n",
    "    else:\n",
    "        return 'ERR'\n",
    "\n",
    "def getHTMLW(merchant):\n",
    "    try:\n",
    "        driver.get('https://google.com/search?q=' + str(merchant) + ' wiki')\n",
    "        html = BeautifulSoup(driver.page_source, \"lxml\")\n",
    "        for res in html.find_all('div', {'class': 'g'}):\n",
    "            if 'wikipedia' in res.find('a').get('href'):\n",
    "                driver.get(res.find('a').get('href'))\n",
    "                return BeautifulSoup(driver.page_source, \"lxml\")\n",
    "        return 'ERR'\n",
    "    except:\n",
    "        return 'ERR'\n",
    "    \n",
    "def findBoxW(html, ret):\n",
    "    try:\n",
    "        return html.find('table', {'class': 'infobox vcard'}).find_all('tr')\n",
    "    except:\n",
    "        try:\n",
    "            return html.find('table', {'class': 'infobox vevent'}).find_all('tr')\n",
    "        except:\n",
    "            try:\n",
    "                return html.find('table', {'class': 'infobox hproduct'}).find_all('tr')\n",
    "            except:\n",
    "                try:\n",
    "                    return html.find('table', {'class': 'infobox'}).find_all('tr')\n",
    "                except:\n",
    "                    return ret\n",
    "\n",
    "def isTradedW(html):\n",
    "    try:\n",
    "        if type(html) == str:\n",
    "            return False\n",
    "        trs = findBoxW(html, False)\n",
    "        for tr in trs:\n",
    "            try:\n",
    "                txt = tr.find('th').text.lower()\n",
    "            except:\n",
    "                continue\n",
    "            if 'traded' in txt:\n",
    "                try:\n",
    "                    return tr.find('a', {'rel':'nofollow'}).text\n",
    "                except:\n",
    "                    try:\n",
    "                        return tr.find('td').text.replace(':', ' ').replace('-', ' ').split()[1]\n",
    "                    except:\n",
    "                        continue\n",
    "        return isTradedW(getParentW(html))\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def isPrivateW(html):\n",
    "    try:\n",
    "        if type(html) == str:\n",
    "            return False\n",
    "        trs = findBoxW(html, False) \n",
    "        for tr in trs:\n",
    "            if 'private' in tr.text.lower():\n",
    "                return True\n",
    "        return isPrivateW(getParentW(html))\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def getParentW(html):\n",
    "    try:\n",
    "        trs = findBoxW(html, 'ERR')\n",
    "        for tr in trs:\n",
    "            try:\n",
    "                txt = tr.find('th').text.lower()\n",
    "            except:\n",
    "                continue\n",
    "            if 'parent' in txt:\n",
    "                path = tr.find('td').find_all('a')[-1].get('href')\n",
    "                if '#' in path:\n",
    "                    path = tr.find('td').find_all('a')[-2].get('href')\n",
    "                driver.get('https://en.wikipedia.org' + path)\n",
    "                return BeautifulSoup(driver.page_source, \"lxml\")\n",
    "        for tr in trs:\n",
    "            try:\n",
    "                txt = tr.find('th').text.lower()\n",
    "            except:\n",
    "                continue\n",
    "            if 'own' in txt or 'developer' in txt or 'successor' in txt:\n",
    "                path = tr.find('td').find_all('a')[-1].get('href')\n",
    "                if '#' in path:\n",
    "                    path = tr.find('td').find_all('a')[-2].get('href')\n",
    "                driver.get('https://en.wikipedia.org' + path)\n",
    "                html = BeautifulSoup(driver.page_source, \"lxml\")\n",
    "                trs = html.find('table', {'class': 'infobox vcard'}).find_all('tr')\n",
    "                for tr in trs:\n",
    "                    if 'born' in tr.text.lower():\n",
    "                        break\n",
    "                    else:\n",
    "                        return html\n",
    "        for tr in trs:\n",
    "            if 'subsidiary of' in tr.text.lower():\n",
    "                try:\n",
    "                    path = tr.find('td').find_all('a')[-1].get('href')\n",
    "                    if '#' in path:\n",
    "                        path = tr.find('td').find_all('a')[-2].get('href')\n",
    "                    driver.get('https://en.wikipedia.org' + path)\n",
    "                    return BeautifulSoup(driver.page_source, \"lxml\")\n",
    "                except:\n",
    "                    return getHTMLW(tr.find('td').text.split('of')[1])\n",
    "        return 'ERR'\n",
    "    except:\n",
    "        return 'ERR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GET_TICKER VERSION 2 EXTENSION (CRUNCHBASE)\n",
    "\n",
    "\n",
    "def getTickerC(merchant):\n",
    "    html = getHTMLC(merchant)\n",
    "    if isTradedC(html) != False:\n",
    "        return isTradedC(html)\n",
    "    if isPrivateC(html):\n",
    "        return 'PRIVATE'\n",
    "    else:\n",
    "        return 'ERR'\n",
    "    \n",
    "def getHTMLC(merchant):\n",
    "    try:\n",
    "        driver.get('https://google.com/search?q=' + str(merchant) + ' crunchbase')\n",
    "        html = BeautifulSoup(driver.page_source, \"lxml\")\n",
    "        for res in html.find_all('div', {'class': 'g'}):\n",
    "            if 'crunchbase' in res.find('a').get('href'):\n",
    "                driver.get(res.find('a').get('href'))\n",
    "                return BeautifulSoup(driver.page_source, \"lxml\")\n",
    "        return 'ERR'\n",
    "    except:\n",
    "        return 'ERR'\n",
    "\n",
    "def isTradedC(html):\n",
    "    try:\n",
    "        if type(html) == str:\n",
    "            return False\n",
    "        if 'public' in html.find_all('fields-card')[1].text.split()[2].lower():\n",
    "            return  html.find_all('fields-card')[1].text.split()[4].split(':')[1]\n",
    "        else:\n",
    "            return isTradedC(getParentC(html))\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "def isPrivateC(html):\n",
    "    try:\n",
    "        if type(html) == str:\n",
    "            return False\n",
    "        if 'private' in html.find_all('fields-card')[1].text.split()[2].lower() or 'delisted' in html.find_all('fields-card')[1].text.split()[2].lower():\n",
    "            return True\n",
    "        else:\n",
    "            return isPrivate(getParent(html))\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def getParentC(html):\n",
    "    try:\n",
    "        spans = html.find_all('fields-card')[0].find_all('span')\n",
    "        for i in range(len(spans)):\n",
    "            try:\n",
    "                if 'Sub-Organization' in spans[i].text:\n",
    "                    driver.get('https://www.crunchbase.com' + spans[i+5].find('a').get('href'))\n",
    "                    return BeautifulSoup(driver.page_source, \"lxml\")\n",
    "            except:\n",
    "                continue\n",
    "        spans = html.find('big-values-card').find_all('span')\n",
    "        for i in range(len(spans)):\n",
    "            try:\n",
    "                if 'Acquired' in spans[i].text:\n",
    "                    driver.get('https://www.crunchbase.com' + spans[i+6].find('a').get('href'))\n",
    "                    return BeautifulSoup(driver.page_source, \"lxml\")\n",
    "            except:\n",
    "                continue\n",
    "        else:\n",
    "            return 'ERR'\n",
    "    except:\n",
    "        return 'ERR'\n",
    "\n",
    "def recentAC(merchant):\n",
    "    try:\n",
    "        html = getHTMLC(merchant)\n",
    "        sections = html.find_all('entity-section')\n",
    "        for section in sections:\n",
    "            if 'Acquisitions' in section.find('div').text:\n",
    "                sub_html = section\n",
    "                break\n",
    "        trs = sub_html.find('list-card').find('tbody').find_all('tr')\n",
    "        acq = []\n",
    "        date = []\n",
    "        price = []\n",
    "        for tr in trs:\n",
    "            acq.append(tr.find_all('td')[0].text)\n",
    "            date.append(tr.find_all('td')[1].text)\n",
    "            price.append(tr.find_all('td')[2].text)\n",
    "        data = {'Acquisition': acq, 'Date': date, 'Price': price}\n",
    "        return pd.DataFrame(data=data)\n",
    "    except:\n",
    "        return 'ERR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMBINING VERSIONS - FINAL VERSION\n",
    "###ENTER w or c for first (for 'Wikipedia' or 'Crunchbase')\n",
    "\n",
    "def getTicker(merchant, first):\n",
    "    if first == 'crunch':\n",
    "        tkr = getTickerC(merchant)\n",
    "        if tkr != 'ERR':\n",
    "            return tkr\n",
    "        else:\n",
    "            return getTickerW(merchant)\n",
    "    if first == 'wiki':\n",
    "        tkr = getTickerW(merchant)\n",
    "        if tkr != 'ERR':\n",
    "            return tkr\n",
    "        else:\n",
    "            return getTickerC(merchant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMPARING THE TWO BOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = pd.read_excel('Completedomains1010_Manual.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = companies['companyName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = []\n",
    "#crunch = []\n",
    "for c in cs:\n",
    "    wiki.append(getTickerW(c))\n",
    "    time.sleep(2.2)\n",
    "    #crunch.append(getTickerC(c))\n",
    "    #time.sleep(2.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'company': cs, 'wiki': wiki, 'crunch': crunch}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['correct'] = companies['ticker_manual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(corr, w, c):\n",
    "    if corr == w and corr == c:\n",
    "        return 'both'\n",
    "    if corr == w:\n",
    "        return 'wiki'\n",
    "    if corr == c:\n",
    "        return 'crunch'\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['who_correct'] = df.apply(lambda x: fun(x['correct'], x['wiki'], x['crunch']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRIVATE    49\n",
       "ERR        33\n",
       "Name: wiki, dtype: int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['wiki'].value_counts().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRIVATE    75\n",
       "ERR         5\n",
       "Name: crunch, dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['crunch'].value_counts().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "both      157\n",
       "wiki       36\n",
       "crunch     21\n",
       "Name: who_correct, dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['who_correct'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('PerformanceReport_getTicker.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
